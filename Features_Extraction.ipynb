{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIYLnA82V0GN812l1M2BGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NorahAbdulaziz/VideoCaptionModel/blob/main/Features_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "FGuUZdGABbG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQNt9aRI2FnH"
      },
      "outputs": [],
      "source": [
        "#Source code from:\n",
        "#https://github.com/Shreyz-max/Video-Captioning/blob/main/extract_features.py\n",
        "def video_to_frames(video):\n",
        "    image_list=[]\n",
        "    videoname=video.split('.')[0]\n",
        "    path = os.path.join(path, videoname)\n",
        "    \n",
        "    for i in os.listdir(path):\n",
        "        cv2.imread(path+\"/\"+i)\n",
        "        image_list.append(path+\"/\"+i)\n",
        "    return image_list\n",
        "\n",
        "def model_cnn_load():\n",
        "    model = VGG16(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n",
        "    out = model.layers[-2].output\n",
        "    model_final = Model(inputs=model.input, outputs=out)\n",
        "    return model_final\n",
        "\n",
        "\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "def extract_features(video, model):\n",
        "    \"\"\"\n",
        "    :param video: The video whose frames are to be extracted to convert into a numpy array\n",
        "    :param model: the pretrained vgg16 model\n",
        "    :return: numpy array of size 4096x80\n",
        "    \"\"\"\n",
        "    video_id = video.split(\".\")[0]\n",
        "    print(video_id)\n",
        "    print(f'Processing video {video}')\n",
        "\n",
        "    image_list = video_to_frames(video)\n",
        "    samples = np.round(np.linspace(\n",
        "        0, len(image_list) - 1, 40))\n",
        "    image_list = [image_list[int(sample)] for sample in samples]\n",
        "    images = np.zeros((len(image_list), 224, 224, 3))\n",
        "    for i in range(len(image_list)):\n",
        "        img = load_image(image_list[i])\n",
        "        images[i] = img\n",
        "    images = np.array(images)\n",
        "    fc_feats = model.predict(images, batch_size=128)\n",
        "    img_feats = np.array(fc_feats)\n",
        "    return img_feats\n",
        "\n",
        "def extract_feats_pretrained_cnn():\n",
        "    \"\"\"\n",
        "    saves the numpy features from all the videos\n",
        "    \"\"\"\n",
        "    model = model_cnn_load()\n",
        "    print('Model loaded')\n",
        "\n",
        "    if not os.path.isdir(os.path.join(path, 'feat')):\n",
        "        os.mkdir(os.path.join(path, 'feat'))\n",
        "    video_list = os.listdir(os.path.join(path, 'feat'))\n",
        "    \n",
        "    for video in video_list:\n",
        "        outfile = os.path.join(path, 'feat', video.split('.')[0] + '.npy')\n",
        "        img_feats = extract_features(video, model)\n",
        "        np.save(outfile, img_feats)\n",
        "\n",
        "extract_feats_pretrained_cnn()"
      ]
    }
  ]
}